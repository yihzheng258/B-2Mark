{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1372dfb9",
   "metadata": {},
   "source": [
    "B2Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8039a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import hashlib\n",
    "\n",
    "g = 8\n",
    "seed = 10000\n",
    "secret_key_1 = \"123\"\n",
    "secret_key_2 = \"456\"\n",
    "threshold = 3\n",
    "watermark_information_length = 8\n",
    "\n",
    "dataset = 'covertype'\n",
    "\n",
    "original_file = '../dataset/covtype_with_key.subset.data'\n",
    "origin = pd.read_csv(original_file)\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "cover_types = origin['Cover_Type'].unique()\n",
    "cover_types.sort()\n",
    "\n",
    "# 计算哈希取模\n",
    "def hash_mod(key, mod_value, secret_key):\n",
    "    combined = f\"{secret_key}{key}\"\n",
    "    hash_value = int(hashlib.sha256(combined.encode()).hexdigest(), 16)\n",
    "    return hash_value % mod_value\n",
    "\n",
    "columns_of_interest = ['Elevation', 'Aspect']\n",
    "origin[columns_of_interest] = origin[columns_of_interest].fillna(0)\n",
    "\n",
    "# 提取前两位非零数字\n",
    "def first_two_digits(x):\n",
    "    if x == 0:\n",
    "        return \"00\"\n",
    "    digits = str(x).lstrip('0.').replace('.', '')\n",
    "    if len(digits) == 1:\n",
    "        return digits + \"0\"\n",
    "    return digits[:2]\n",
    "\n",
    "# 测试不同数量文件的检测时间\n",
    "file_counts = [16, 32, 48, 64, 80, 96, 112, 128]\n",
    "timing_results = {}\n",
    "\n",
    "data_path = \"different_version_datasets/original\"\n",
    "\n",
    "for file_count in file_counts:\n",
    "    print(f\"Processing {file_count} files...\")\n",
    "    total_time = 0  # 累计时间\n",
    "    selected_files = sorted(os.listdir(data_path))[:file_count]  # 按顺序取前 file_count 个文件\n",
    "\n",
    "    for file_name in selected_files:\n",
    "        if file_name.startswith(\"covertype-\"):\n",
    "            start_time = time.time()  # 开始计时\n",
    "\n",
    "            watermarked_data = np.load(f\"{data_path}/{file_name}\", allow_pickle=True).item() \n",
    "            watermarked_data = watermarked_data['watermarked_data']\n",
    "\n",
    "            detected_watermark_information = \"\"\n",
    "            watermarked_data[columns_of_interest] = watermarked_data[columns_of_interest].fillna(0)\n",
    "\n",
    "            green_cells = np.zeros(watermark_information_length)\n",
    "            n_cells = np.zeros(watermark_information_length)\n",
    "            z_scores = np.zeros(watermark_information_length)\n",
    "\n",
    "            # 遍历数据进行检测\n",
    "            for idx in range(len(watermarked_data)):\n",
    "                selected_data = watermarked_data.loc[idx, columns_of_interest]\n",
    "                first_two_digits_data = selected_data.apply(first_two_digits)\n",
    "                composite_numbers = ''.join(first_two_digits_data.values)\n",
    "\n",
    "                w_index = hash_mod(composite_numbers, watermark_information_length, secret_key_1)\n",
    "\n",
    "                if hash_mod(composite_numbers, g, secret_key_2) == 0:\n",
    "                    n_cells[w_index] += 1\n",
    "                    if watermarked_data.loc[idx, 'Cover_Type'] in green_domain:\n",
    "                        green_cells[w_index] += 1\n",
    "\n",
    "            # 计算 z_scores\n",
    "            for idx in range(watermark_information_length):\n",
    "                if n_cells[idx] != 0:\n",
    "                    z_scores[idx] = (green_cells[idx] - n_cells[idx] / 2) / math.sqrt(n_cells[idx] / 4)\n",
    "                else:\n",
    "                    z_scores[idx] = 0\n",
    "\n",
    "            # 更新检测水印信息\n",
    "            for idx in range(len(z_scores)):\n",
    "                if z_scores[idx] > threshold:\n",
    "                    detected_watermark_information += '1'\n",
    "                else:\n",
    "                    detected_watermark_information += '0'\n",
    "\n",
    "            end_time = time.time()  # 结束计时\n",
    "            total_time += (end_time - start_time)  # 累计时间\n",
    "\n",
    "    # 求平均时间\n",
    "    average_time = total_time / file_count\n",
    "    timing_results[file_count] = average_time\n",
    "    print(f\"Average time for {file_count} files: {average_time:.2f} seconds\\n\")\n",
    "\n",
    "# 打印总结果\n",
    "print(\"Timing results:\")\n",
    "for file_count, duration in timing_results.items():\n",
    "    print(f\"{file_count} files: {duration:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a041c6",
   "metadata": {},
   "source": [
    "TabularMark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87403647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "\n",
    "seed_start = 10000\n",
    "seed_end = 10000 + 128  # 总共 128 份文件\n",
    "dataset = 'covertype'\n",
    "threshold = 3\n",
    "\n",
    "original_file = '../dataset/covtype_with_key.subset.data'\n",
    "origin = pd.read_csv(original_file)\n",
    "\n",
    "n = int(len(origin) / 8)\n",
    "gamma = 1 / 2\n",
    "\n",
    "primary_key_cols = ['Elevation', 'Aspect']\n",
    "\n",
    "# 二分查找函数\n",
    "def binary_search(arr, key):\n",
    "    left, right = 0, len(arr) - 1\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "        if arr[mid] == key:\n",
    "            return mid\n",
    "        elif arr[mid] < key:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "    return -1\n",
    "\n",
    "# 匹配元组函数\n",
    "def match_tuples(origin_data, watermarked_data, indices):\n",
    "    match_indices = []\n",
    "    watermarked_keys = [tuple(row) for row in watermarked_data[primary_key_cols].values]\n",
    "    for idx in indices:\n",
    "        key_do = tuple(origin_data.loc[idx, primary_key_cols])\n",
    "        match_idx = binary_search(watermarked_keys, key_do)\n",
    "        if match_idx != -1:\n",
    "            match_indices.append(watermarked_data.index[match_idx])\n",
    "        else:\n",
    "            match_indices.append(-1)\n",
    "    return match_indices\n",
    "\n",
    "# 测试不同数量文件所需时间\n",
    "file_counts = [16, 32, 48, 64, 80, 96, 112, 128]\n",
    "timing_results = {}\n",
    "\n",
    "\n",
    "for file_count in file_counts:\n",
    "    print(f\"Processing {file_count} files...\")\n",
    "    \n",
    "    random_files = np.random.choice(file_count, 10, replace=False)\n",
    "    \n",
    "    timing_results[file_count] = 0\n",
    "    for file in random_files:\n",
    "        start_time = time.time()  # 开始计时\n",
    "        watermarked_data = np.load(f\"different_version_datasets/tabularmark/{dataset}-{file+10000}.npy\", allow_pickle=True).item()\n",
    "        watermarked_data = watermarked_data['watermarked_data']\n",
    "        watermarked_data = watermarked_data.sort_values(by=primary_key_cols).reset_index(drop=True)\n",
    "    \n",
    "        for seed in range(seed_start, seed_start + file_count):\n",
    "            loaded_results = np.load(f\"different_version_datasets/tabularmark/{dataset}-{seed}.npy\", allow_pickle=True).item()\n",
    "\n",
    "            divide_seeds = loaded_results['divide_seeds']\n",
    "            indices = loaded_results['indices']\n",
    "            \n",
    "            cover_types = watermarked_data['Cover_Type'].unique()\n",
    "            cover_types.sort()\n",
    "\n",
    "            match_indices = match_tuples(origin, watermarked_data, indices)\n",
    "            green_cell = 0\n",
    "            for idx, divide_seed in zip(match_indices, divide_seeds):\n",
    "                np.random.seed(divide_seed)\n",
    "                candidate_set = cover_types\n",
    "\n",
    "                shuffled_cover_types = list(cover_types)\n",
    "                np.random.shuffle(shuffled_cover_types)\n",
    "\n",
    "                half_size = len(shuffled_cover_types) // 2\n",
    "\n",
    "                green_domain = shuffled_cover_types[:half_size]\n",
    "                red_domain = shuffled_cover_types[half_size:]\n",
    "\n",
    "                if idx != -1 and watermarked_data.loc[idx, 'Cover_Type'] in green_domain:\n",
    "                    green_cell += 1\n",
    "\n",
    "            z_score = (green_cell - n / 2) / math.sqrt(n / 4)\n",
    "            if(z_score > threshold):\n",
    "                break\n",
    "        end_time = time.time()  # 结束计时\n",
    "        # print(f\"Time taken for {seed - seed_start} files: {end_time - start_time:.2f} seconds\")\n",
    "        timing_results[file_count] += end_time - start_time\n",
    "    timing_results[file_count] = timing_results[file_count] / 10\n",
    "    print(f\"Time taken for {file_count} files: {timing_results[file_count]:.2f} seconds\\n\")\n",
    "\n",
    "# 打印总结果\n",
    "print(\"Timing results:\")\n",
    "for file_count, duration in timing_results.items():\n",
    "    print(f\"{file_count} files: {duration:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
