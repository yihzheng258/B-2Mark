{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28cddc07",
   "metadata": {},
   "source": [
    "Generate watermarked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad05e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "from watermarking_schemes.B2Mark import WatermarkEmbedding\n",
    "\n",
    "# B2Mark\n",
    "\n",
    "seed_range = range(10000, 10010)\n",
    "\n",
    "# 随机生成n个单位长度为 6 的字符串数组secret_key_1s与secret_key_2s\n",
    "\n",
    "def generate_secret_keys(n, length=6):\n",
    "    np.random.seed(99)  # 设置随机种子\n",
    "    charset = list(string.ascii_letters + string.digits)  # 转换成字符列表\n",
    "    secret_key_1s = [''.join(np.random.choice(charset, size=length)) for _ in range(n)]\n",
    "    secret_key_2s = [''.join(np.random.choice(charset, size=length)) for _ in range(n)]\n",
    "    return secret_key_1s, secret_key_2s\n",
    "\n",
    "g = 6\n",
    "\n",
    "secret_key_1s, secret_key_2s = generate_secret_keys(30)\n",
    "\n",
    "for idx, seed in enumerate(seed_range):\n",
    "    dataset = \"covertype\"\n",
    "    original_data_path = f\"dataset/covtype_with_key.subset.data\"\n",
    "    \n",
    "    b2Mark_embedding = WatermarkEmbedding(dataset = dataset, watermark_information=\"1010110011\", g = g, seed = 10000, secret_key_1=secret_key_1s[0], secret_key_2=secret_key_2s[0], original_file=original_data_path)                                         \n",
    "    b2Mark_embedding.load_dataset()\n",
    "    b2Mark_embedding.get_quality_domains()\n",
    "    b2Mark_embedding.apply_watermark()\n",
    "    b2Mark_embedding.save_results(f\"B2Mark_dataset/B2Mark_{dataset}_{seed}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    " \n",
    "from watermarking_schemes.GAHSW import WatermarkEmbedding\n",
    "\n",
    "dataset = \"covertype\"\n",
    "\n",
    "def generate_secret_keys(n, length=6):\n",
    "    np.random.seed(99)  # 设置随机种子\n",
    "    charset = list(string.ascii_letters + string.digits)  # 转换成字符列表\n",
    "    secret_key_1s = [''.join(np.random.choice(charset, size=length)) for _ in range(n)]\n",
    "    secret_key_2s = [''.join(np.random.choice(charset, size=length)) for _ in range(n)]\n",
    "    return secret_key_1s, secret_key_2s\n",
    "\n",
    "secret_key_1s, secret_key_2s = generate_secret_keys(30)\n",
    "\n",
    "watermark_information=\"1010110011\"\n",
    "\n",
    "for idx, seed in enumerate(range(10000, 10010)):\n",
    "    original_file = f'dataset/covtype_with_key.subset.data'\n",
    "\n",
    "    gahsw_embedding = WatermarkEmbedding(dataset=dataset, watermark_information=watermark_information, seed=10000, original_file=original_file, Ks=secret_key_1s[0], N_g=len(watermark_information))\n",
    "    gahsw_embedding.load_dataset()\n",
    "    gahsw_embedding.apply_watermark()\n",
    "    gahsw_embedding.save_results(f\"GAHSW_dataset/GAHSW_{dataset}_{seed}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bddb965",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "from watermarking_schemes.SCPW import WatermarkEmbedding\n",
    "\n",
    "dataset = \"covertype\"\n",
    "\n",
    "def generate_secret_keys(n, length=6):\n",
    "    np.random.seed(99)  # 设置随机种子\n",
    "    charset = list(string.ascii_letters + string.digits)  # 转换成字符列表\n",
    "    secret_key_1s = [''.join(np.random.choice(charset, size=length)) for _ in range(n)]\n",
    "    secret_key_2s = [''.join(np.random.choice(charset, size=length)) for _ in range(n)]\n",
    "    return secret_key_1s, secret_key_2s\n",
    "\n",
    "secret_key_1s, secret_key_2s = generate_secret_keys(30)\n",
    "\n",
    "watermark_information=\"1010110011\"\n",
    "\n",
    "\n",
    "for idx, seed in enumerate(range(10000, 10010)):\n",
    "    orginal_file = f\"dataset/covtype_with_key.subset.data\"\n",
    "\n",
    "    scpw_embedding = WatermarkEmbedding(dataset=dataset, watermark_information=watermark_information, seed=10000, original_file=orginal_file, Ks=secret_key_1s[1])\n",
    "    scpw_embedding.load_dataset()\n",
    "    scpw_embedding.apply_watermark()\n",
    "    scpw_embedding.save_results(f\"SCPW_dataset/SCPW_{dataset}_{seed}.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c69384",
   "metadata": {},
   "source": [
    "align the non-intrusiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a03c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "\n",
    "class MLUtilityXGBoost:\n",
    "  \n",
    "    def __init__(self, dataset_path, watermarked_data_path=None, test_size=0.3, random_state=42):\n",
    "        \n",
    "        self.dataset_path = dataset_path\n",
    "        self.watermarked_data_path = watermarked_data_path\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.model = xgb.XGBClassifier(n_estimators=30, max_depth=10, n_jobs=4)\n",
    "\n",
    "    def load_data(self, file_path):\n",
    "        _, file_extension = os.path.splitext(file_path)\n",
    "        data = None\n",
    "        if file_extension == '.npy':\n",
    "            loaded_results = np.load(file_path, allow_pickle=True).item()\n",
    "            data = loaded_results['watermarked_data']\n",
    "        else:\n",
    "            data = pd.read_csv(file_path)\n",
    "        return data\n",
    "\n",
    "    def preprocess_data(self, data):\n",
    "        X = data.drop(columns=['Cover_Type'])\n",
    "        y = data['Cover_Type']\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "        return X, y\n",
    "\n",
    "    def split_data(self, X, y):\n",
    "        return train_test_split(X, y, test_size=self.test_size, random_state=self.random_state)\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict_and_evaluate(self, X_test, y_test):\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        return f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "    def compute_f1(self):\n",
    "        # 加载原始数据\n",
    "        origin_data = self.load_data(self.dataset_path)\n",
    "        origin_data = origin_data.drop(columns=['primary_key'])\n",
    "        X_origin, y_origin = self.preprocess_data(origin_data)\n",
    "        X_train, X_test, y_train, y_test = self.split_data(X_origin, y_origin)\n",
    "\n",
    "        # 训练模型并评估 F1-score\n",
    "        self.train_model(X_train, y_train)\n",
    "        f1_origin = self.predict_and_evaluate(X_test, y_test)\n",
    "        # print(f\"F1-score on original data: {f1_origin:.4f}\")\n",
    "        \n",
    "\n",
    "        # 如果水印数据路径提供了，加载水印数据并计算 F1-score\n",
    "        if self.watermarked_data_path:\n",
    "            watermarked_data = self.load_data(self.watermarked_data_path)\n",
    "            watermarked_data = watermarked_data[origin_data.columns]\n",
    "            X_watermarked, y_watermarked = self.preprocess_data(watermarked_data)\n",
    "            X_train, _, y_train, _ = self.split_data(X_watermarked, y_watermarked)\n",
    "\n",
    "            # 训练模型并评估 F1-score\n",
    "            self.train_model(X_train, y_train)\n",
    "            f1_watermarked = self.predict_and_evaluate(X_test, y_test)\n",
    "            # print(f\"F1-score on watermarked data: {f1_watermarked:.4f}\")\n",
    "        \n",
    "        return f1_watermarked, f1_origin\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5eb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "watermark_schemes = ['B2Mark', 'GAHSW', 'SCPW']\n",
    "\n",
    "for watermark_scheme in watermark_schemes:\n",
    "    dataset = \"covertype\"\n",
    "    dataset_path = \"dataset/covtype_with_key.subset.data\"\n",
    "    \n",
    "    f1_scores = []\n",
    "    f1_scores_origin = []\n",
    "    for seed in range(10000,10010):\n",
    "        watermarked_data_path = f\"{watermark_scheme}_dataset/{watermark_scheme}_{dataset}_{seed}.npy\"\n",
    "        \n",
    "        measure_ml_util = MLUtilityXGBoost(dataset_path, watermarked_data_path)\n",
    "        f1, f1_origin = measure_ml_util.compute_f1()\n",
    "        f1_scores.append(f1)\n",
    "        f1_scores_origin.append(f1_origin)\n",
    "        \n",
    "    print(f\"Watermark scheme: {watermark_scheme}\")\n",
    "    print(f\"Mean F1: {np.mean(f1_scores):.4f}\")\n",
    "    print(f\"Mean F1 Origin: {np.mean(f1_scores_origin):.4f}\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebac4cf",
   "metadata": {},
   "source": [
    "attack and compute BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d51a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class AlterationNumericalAttack:\n",
    "    \n",
    "    def __init__(self, watermarked_data_path, attack_proportions=None, dataset='covertype', p=3, perturbed_attribute = 'Cover_Type', random_seed=10000):\n",
    "\n",
    "        self.watermarked_data_path = watermarked_data_path\n",
    "        self.attack_proportions = attack_proportions if attack_proportions is not None else [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        self.p = p\n",
    "        self.random_seed = random_seed\n",
    "        self.perturbed_attribute = perturbed_attribute\n",
    "        self.dataset = dataset\n",
    "        np.random.seed(self.random_seed)\n",
    "        \n",
    "        # 加载水印数据\n",
    "        self.loaded_results = np.load(self.watermarked_data_path, allow_pickle=True).item()\n",
    "        self.watermarked_data = self.loaded_results['watermarked_data']\n",
    "        \n",
    "    def apply_attack(self, proportion, save_path):\n",
    "\n",
    "        temp = self.watermarked_data.copy()\n",
    "        indices = np.random.choice(len(temp), size=int(proportion * len(temp)), replace=False)\n",
    "        perturb_values = np.random.uniform(-self.p, self.p, size=len(indices))  # 扰动值\n",
    "        perturb_values = perturb_values.round(0)\n",
    "        perturb_choices = np.arange(1, 8)  # 假设 CoverType 的值范围是 1 到 7\n",
    "        perturb_values = np.random.choice(perturb_choices, size=len(indices))\n",
    "\n",
    "        temp.loc[indices, self.perturbed_attribute] = perturb_values\n",
    "        self.loaded_results['watermarked_data'] = temp\n",
    "        np.save(save_path, self.loaded_results)\n",
    "\n",
    "    def execute(self, save_path):\n",
    "        for proportion in self.attack_proportions:\n",
    "            self.apply_attack(proportion, save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2369104",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test robustness\n",
    "attack_range = [3]\n",
    "attack_proportions = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "seeds = range(10000, 10010)\n",
    "dataset = \"covertype\"\n",
    "watermark_schemes = ['B2Mark', 'GAHSW', 'SCPW']\n",
    "\n",
    "for watermark_scheme in watermark_schemes:\n",
    "    for p in attack_range:\n",
    "            for attack_proportion in attack_proportions:\n",
    "                for seed in seeds:\n",
    "                    watermarked_data_path = f\"{watermark_scheme}_dataset/{watermark_scheme}_{dataset}_{seed}.npy\"\n",
    "                    save_path = f\"{watermark_scheme}_dataset/{watermark_scheme}_{dataset}_{seed}_{p}_{attack_proportion}.npy\"\n",
    "                    AlterationNumericalAttack(watermarked_data_path, attack_proportions=[attack_proportion], dataset=dataset, p=p, random_seed=seed).execute(save_path)\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d95dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from watermarking_schemes.B2Mark import WatermarkDetection\n",
    "\n",
    "seed_range = range(10000, 10010)\n",
    "\n",
    "# 随机生成n个单位长度为 6 的字符串数组secret_key_1s与secret_key_2s\n",
    "\n",
    "def generate_secret_keys(n, length=6):\n",
    "    np.random.seed(99)  # 设置随机种子\n",
    "    charset = list(string.ascii_letters + string.digits)  # 转换成字符列表\n",
    "    secret_key_1s = [''.join(np.random.choice(charset, size=length)) for _ in range(n)]\n",
    "    secret_key_2s = [''.join(np.random.choice(charset, size=length)) for _ in range(n)]\n",
    "    return secret_key_1s, secret_key_2s\n",
    "\n",
    "g = 6\n",
    "\n",
    "secret_key_1s, secret_key_2s = generate_secret_keys(30)\n",
    "\n",
    "attack_range = [3]\n",
    "attack_proportions = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "original_data_path = \"dataset/covtype_with_key.subset.data\"\n",
    "\n",
    "watermark_information=\"1010110011\"\n",
    "dataset = \"covertype\"\n",
    "\n",
    "for p in attack_range:\n",
    "    for attack_proportion in attack_proportions:\n",
    "        BERs = [] \n",
    "        for idx, seed in enumerate(seed_range):\n",
    "            file_path = f\"B2Mark_dataset/B2Mark_{dataset}_{seed}_{p}_{attack_proportion}.npy\"\n",
    "            b2Mark_detection = WatermarkDetection(dataset=dataset, seed=seed , g=g, secret_key_1=secret_key_1s[idx], secret_key_2=secret_key_2s[idx], watermark_information=\"1010110011\",threshold=3)\n",
    "            detected_watermark = b2Mark_detection.run_detection(file_path) \n",
    "            z_scores = b2Mark_detection.get_z_scores()\n",
    "\n",
    "            # 计算 detected_watermark的BER\n",
    "            detected_bits = np.array(list(map(int, detected_watermark)))\n",
    "            true_bits = np.array(list(map(int, watermark_information)))\n",
    "\n",
    "            ber = np.sum(detected_bits != true_bits) / len(true_bits)\n",
    "            BERs.append(ber)\n",
    "    \n",
    "      \n",
    "        print(f\"p: {attack_proportion}, BER: {np.mean(BERs):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from watermarking_schemes.GAHSW import WatermarkDetection\n",
    "\n",
    "seed_range = range(10000, 10010)\n",
    "\n",
    "# 随机生成n个单位长度为 6 的字符串数组secret_key_1s与secret_key_2s\n",
    "\n",
    "def generate_secret_keys(n, length=6):\n",
    "    np.random.seed(99)  # 设置随机种子\n",
    "    charset = list(string.ascii_letters + string.digits)  # 转换成字符列表\n",
    "    secret_key_1s = [''.join(np.random.choice(charset, size=length)) for _ in range(n)]\n",
    "    secret_key_2s = [''.join(np.random.choice(charset, size=length)) for _ in range(n)]\n",
    "    return secret_key_1s, secret_key_2s\n",
    "\n",
    "g = 2\n",
    "\n",
    "secret_key_1s, secret_key_2s = generate_secret_keys(30)\n",
    "\n",
    "attack_range = [3]\n",
    "# attack_proportions = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "attack_proportions = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "\n",
    "original_data_path = \"dataset/covtype_with_key.subset.data\"\n",
    "\n",
    "watermark_information=\"1010110011\"\n",
    "dataset = \"covertype\"\n",
    "\n",
    "for p in attack_range:\n",
    "    for attack_proportion in attack_proportions:\n",
    "        # detected_watermarks = [] \n",
    "        BERs = []\n",
    "        for idx, seed in enumerate(seed_range):\n",
    "            file_path = f\"GAHSW_dataset/GAHSW_{dataset}_{seed}_{p}_{attack_proportion}.npy\"\n",
    "            gahsw_detection = WatermarkDetection(dataset=dataset, watermark_information=\"1010110011\", seed=seed, Ks=secret_key_1s[idx])\n",
    "            detected_watermark = gahsw_detection.run_detection(file_path) \n",
    "            detected_bits = np.array(list(map(int, detected_watermark)))\n",
    "            true_bits = np.array(list(map(int, watermark_information)))\n",
    "\n",
    "            ber = np.sum(detected_bits != true_bits) / len(true_bits)\n",
    "            BERs.append(ber)\n",
    "\n",
    "       \n",
    "        print(f\"p: {attack_proportion}, BER: {np.mean(BERs):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df08249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from watermarking_schemes.SCPW import WatermarkDetection\n",
    "\n",
    "\n",
    "seed_range = range(10000, 10010)\n",
    "\n",
    "# 随机生成n个单位长度为 6 的字符串数组secret_key_1s与secret_key_2s\n",
    "\n",
    "def generate_secret_keys(n, length=6):\n",
    "    np.random.seed(99)  # 设置随机种子\n",
    "    charset = list(string.ascii_letters + string.digits)  # 转换成字符列表\n",
    "    secret_key_1s = [''.join(np.random.choice(charset, size=length)) for _ in range(n)]\n",
    "    secret_key_2s = [''.join(np.random.choice(charset, size=length)) for _ in range(n)]\n",
    "    return secret_key_1s, secret_key_2s\n",
    "\n",
    "\n",
    "secret_key_1s, secret_key_2s = generate_secret_keys(30)\n",
    "\n",
    "attack_range = [3]\n",
    "# attack_proportions = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "attack_proportions = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "original_data_path = \"dataset/covtype_with_key.subset.data\"\n",
    "\n",
    "watermark_information=\"1010110011\"\n",
    "dataset = \"covertype\"\n",
    "\n",
    "for p in attack_range:\n",
    "    for attack_proportion in attack_proportions:\n",
    "        # detected_watermarks = [] \n",
    "        BERs = []\n",
    "        for idx, seed in enumerate(seed_range):\n",
    "            file_path = f\"SCPW_dataset/SCPW_{dataset}_{seed}_{p}_{attack_proportion}.npy\"\n",
    "            scpw_detection = WatermarkDetection(dataset=dataset, watermark_information=\"1010110011\", seed=seed, Ks=secret_key_1s[idx])\n",
    "            detected_watermark = scpw_detection.run_detection(file_path) \n",
    "            # detected_watermarks.append(detected_watermark)\n",
    "            detected_bits = np.array(list(map(int, detected_watermark)))\n",
    "            true_bits = np.array(list(map(int, watermark_information)))\n",
    "\n",
    "            ber = np.sum(detected_bits != true_bits) / len(true_bits)\n",
    "            BERs.append(ber)\n",
    "\n",
    "        print(f\"p: {attack_proportion}, BER: {np.mean(BERs):.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
