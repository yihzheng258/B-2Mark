{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split iris data into train and test sets\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"dataset/iris.csv\")\n",
    "\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "train_df = X_train.copy()\n",
    "train_df['class'] = y_train\n",
    "\n",
    "test_df = X_test.copy()\n",
    "test_df['class'] = y_test\n",
    "\n",
    "train_df.to_csv(\"dataset/iris_train.csv\", index=False)\n",
    "test_df.to_csv(\"dataset/iris_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watermarking_schemes.B2Mark import B2MarkWatermarkEmbedding\n",
    "g_s = [2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "for g in g_s:\n",
    "    for seed in range(10000,10100):\n",
    "        wm = B2MarkWatermarkEmbedding(\n",
    "            dataset=\"iris\",\n",
    "            seed=seed,\n",
    "            g=g,\n",
    "            gamma=1/2,\n",
    "            secret_key=\"123\",\n",
    "            columns_of_interest=['sepal_length', 'sepal_width'],\n",
    "            label_column='class'\n",
    "        )\n",
    "        wm.load_data('dataset/iris_train.csv')\n",
    "        wm.process_data()\n",
    "        wm.save_results(f'dataset/iris_train_{g}_{seed}.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline (No Watermark, Trained 100x) ===\n",
      "Clean Test Acc: 90.13% ± 4.11%\n",
      "FGSM  Test Acc: 83.83% ± 4.56%\n",
      "=== Watermarked Summary (grouped by g) ===\n",
      "g=2  | Clean Acc: 52.37% | FGSM Acc: 43.10% | seeds: 100\n",
      "g=3  | Clean Acc: 81.23% | FGSM Acc: 72.30% | seeds: 100\n",
      "g=4  | Clean Acc: 87.73% | FGSM Acc: 78.93% | seeds: 100\n",
      "g=5  | Clean Acc: 87.27% | FGSM Acc: 77.97% | seeds: 100\n",
      "g=6  | Clean Acc: 92.70% | FGSM Acc: 84.67% | seeds: 100\n",
      "g=7  | Clean Acc: 90.57% | FGSM Acc: 82.87% | seeds: 100\n",
      "g=8  | Clean Acc: 91.87% | FGSM Acc: 83.17% | seeds: 100\n",
      "g=9  | Clean Acc: 89.10% | FGSM Acc: 81.83% | seeds: 100\n",
      "g=10 | Clean Acc: 93.33% | FGSM Acc: 86.27% | seeds: 100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# ===== 1. 定义 MLP 模型 =====\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=4, hidden_dim=16, output_dim=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    def forward(self, x): \n",
    "        return self.net(x)\n",
    "\n",
    "# ===== 2. FGSM 攻击函数 =====\n",
    "def fgsm_attack(model, loss_fn, x, y, epsilon=0.1):\n",
    "    x_adv = x.clone().detach().requires_grad_(True)\n",
    "    output = model(x_adv)\n",
    "    loss = loss_fn(output, y)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    # 沿梯度符号方向扰动\n",
    "    x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
    "    # 适当裁剪，避免数值越界\n",
    "    return torch.clamp(x_adv, -5, 5).detach()\n",
    "\n",
    "# ===== 3. 训练函数 =====\n",
    "def train_model(X_train, y_train, epochs=50, lr=0.01):\n",
    "    model = MLP()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        out = model(X_train)\n",
    "        loss = loss_fn(out, y_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "# ===== 4. 测试函数 =====\n",
    "def evaluate_model(model, X, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X).argmax(dim=1)\n",
    "    return accuracy_score(y.numpy(), preds.numpy())\n",
    "\n",
    "# ===== 5. 加载并预处理 CSV 数据 =====\n",
    "def load_iris_data(csv_path):\n",
    "    \"\"\" 返回预处理好的 (X_tensor, y_tensor) \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    X = df.drop(columns=['class']).values\n",
    "    y = df['class'].values\n",
    "\n",
    "    # LabelEncoder 方便将字符串标签转为 int\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)  # 0,1,2\n",
    "    \n",
    "    # 标准化\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "    return X_tensor, y_tensor\n",
    "\n",
    "def main():\n",
    "    # 加载统一的测试集和训练集（不重新划分）\n",
    "    X_test, y_test = load_iris_data(\"dataset/iris_test.csv\")\n",
    "    X_train, y_train = load_iris_data(\"dataset/iris_train.csv\")\n",
    "\n",
    "    # 保存每次的准确率\n",
    "    acc_clean_list = []\n",
    "    acc_fgsm_list = []\n",
    "\n",
    "    for trial in range(100):\n",
    "        model = train_model(X_train, y_train)\n",
    "        \n",
    "        acc_clean = evaluate_model(model, X_test, y_test)\n",
    "        acc_clean_list.append(acc_clean)\n",
    "\n",
    "        X_test_adv = fgsm_attack(model, nn.CrossEntropyLoss(), X_test, y_test, epsilon=0.1)\n",
    "        acc_fgsm = evaluate_model(model, X_test_adv, y_test)\n",
    "        acc_fgsm_list.append(acc_fgsm)\n",
    "\n",
    "    # 统计结果\n",
    "    acc_clean_mean = np.mean(acc_clean_list)\n",
    "    acc_clean_std  = np.std(acc_clean_list)\n",
    "\n",
    "    acc_fgsm_mean = np.mean(acc_fgsm_list)\n",
    "    acc_fgsm_std  = np.std(acc_fgsm_list)\n",
    "\n",
    "    # 打印\n",
    "    print(\"=== Baseline (No Watermark, Trained 100x) ===\")\n",
    "    print(f\"Clean Test Acc: {acc_clean_mean:.2%} ± {acc_clean_std:.2%}\")\n",
    "    print(f\"FGSM  Test Acc: {acc_fgsm_mean:.2%} ± {acc_fgsm_std:.2%}\")\n",
    "\n",
    "\n",
    "\n",
    "    # 存储不同 g 下的 seed 结果\n",
    "    results_by_g = defaultdict(list)\n",
    "\n",
    "    g_s = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    seeds = range(10000, 10100)\n",
    "\n",
    "    for g in g_s:\n",
    "        for seed in seeds:\n",
    "            path = f\"dataset/iris_train_{g}_{seed}.csv\"\n",
    "            try:\n",
    "                X_train_wm, y_train_wm = load_iris_data(path)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "\n",
    "            model = train_model(X_train_wm, y_train_wm)\n",
    "            acc_clean = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "            # 使用水印模型生成自己对应的对抗样本\n",
    "            X_test_adv = fgsm_attack(model, nn.CrossEntropyLoss(), X_test, y_test, epsilon=0.1)\n",
    "            acc_adv = evaluate_model(model, X_test_adv, y_test)\n",
    "            \n",
    "            \n",
    "\n",
    "            results_by_g[g].append((acc_clean, acc_adv))\n",
    "\n",
    "    # 平均输出\n",
    "    print(\"=== Watermarked Summary (grouped by g) ===\")\n",
    "    for g in sorted(results_by_g.keys()):\n",
    "        arr = np.array(results_by_g[g])\n",
    "        clean_mean = arr[:, 0].mean()\n",
    "        adv_mean = arr[:, 1].mean()\n",
    "        print(f\"g={g:<2d} | Clean Acc: {clean_mean:.2%} | FGSM Acc: {adv_mean:.2%} | seeds: {len(arr)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watermark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
