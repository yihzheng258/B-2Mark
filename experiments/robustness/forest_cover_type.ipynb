{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alteration attack\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "seed = 10000\n",
    "np.random.seed(seed)\n",
    "attack_proportion = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "dataset = \"covertype\"\n",
    "loaded_results = np.load(f\"{dataset}-{seed}.npy\", allow_pickle=True).item()\n",
    "watermarked_data = loaded_results['watermarked_data']\n",
    "\n",
    "cover_types = watermarked_data['Cover_Type'].unique()\n",
    "cover_types.sort()\n",
    "\n",
    "np.random.seed(111)\n",
    "for proportion in attack_proportion:\n",
    "        temp = watermarked_data.copy()\n",
    "        indices = np.random.choice(len(temp), size=int(proportion * len(temp)), replace=False)\n",
    "        perturb_values = np.random.choice(cover_types, size=int(proportion * len(temp)))\n",
    "        temp.loc[indices, 'Cover_Type'] = perturb_values\n",
    "        temp.to_csv(f\"alteration_{dataset}-{seed}-{proportion}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect alteration\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "dataset = 'covertype'\n",
    "seed = 10000\n",
    "\n",
    "gamma = 1/2 # ratio between the length of green domain and red domain\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "origin = pd.read_csv(\"../dataset/covtype_with_key.subset.data\")\n",
    "\n",
    "proportions = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "for proportion in proportions:\n",
    "    loaded_results = np.load(f\"{dataset}-{seed}.npy\", allow_pickle=True).item()\n",
    "    watermarked_data = pd.read_csv(f\"alteration_{dataset}-{seed}-{proportion}.csv\")\n",
    "\n",
    "    cover_types = watermarked_data['Cover_Type'].unique()\n",
    "    cover_types.sort()  \n",
    "\n",
    "    green_cell = 0\n",
    "    n_cell = 0\n",
    "    \n",
    "    for idx in range(len(watermarked_data)):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        \n",
    "        selected_data = watermarked_data.loc[idx, columns_of_interest]\n",
    "        first_two_digits_data = selected_data.apply(first_two_digits)\n",
    "        composite_numbers = ''.join(first_two_digits_data.values)\n",
    "        \n",
    "        if(hash_mod(composite_numbers, 10) != 0):\n",
    "            continue\n",
    "        \n",
    "        n_cell += 1\n",
    "        \n",
    "        candidate_set = cover_types\n",
    "\n",
    "        shuffled_cover_types = list(cover_types)\n",
    "        np.random.shuffle(shuffled_cover_types)\n",
    "\n",
    "        half_size = len(shuffled_cover_types) // 2\n",
    "        green_domain = shuffled_cover_types[:half_size]\n",
    "        red_domain = shuffled_cover_types[half_size:]\n",
    "\n",
    "        if watermarked_data.loc[idx, 'Cover_Type'] in green_domain:\n",
    "            green_cell += 1\n",
    "    \n",
    "    # print(n_cell)\n",
    "    z_score = (green_cell - n_cell/2) / math.sqrt(n_cell/4)\n",
    "    print(f\"{proportion}: The z-score is \", z_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "dataset = 'covertype'\n",
    "seed = 10000\n",
    "\n",
    "gamma = 1/2 # ratio between the length of green domain and red domain\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "origin = pd.read_csv(\"../dataset/covtype_with_key.subset.data\")\n",
    "\n",
    "proportions = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "for proportion in proportions:\n",
    "    loaded_results = np.load(f\"{dataset}-{seed}.npy\", allow_pickle=True).item()\n",
    "    watermarked_data = pd.read_csv(f\"alteration_{dataset}-{seed}-{proportion}.csv\")\n",
    "\n",
    "    cover_types = watermarked_data['Cover_Type'].unique()\n",
    "    cover_types.sort()  \n",
    "\n",
    "    X = watermarked_data.drop(columns=['Cover_Type'])\n",
    "    y = watermarked_data['Cover_Type']\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "    X_train, _, y_train, _ = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    X = origin.drop(columns=['Cover_Type'])\n",
    "    y = origin['Cover_Type']\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "    _, X_test, _, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    model = xgb.XGBClassifier(n_estimators=30, max_depth=10, n_jobs=4)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    f1_scores = f1_score(y_test, y_pred, average=None)\n",
    "    print(f\"{proportion}:\")\n",
    "    for i, score in enumerate(f1_scores):\n",
    "        print(f\"Category {le.inverse_transform([i])[0]}: F1-score = {score:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertion attack\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "seed = 10000\n",
    "np.random.seed(seed)\n",
    "attack_proportion = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "dataset = \"covertype\"\n",
    "loaded_results = np.load(f\"{dataset}-{seed}.npy\", allow_pickle=True).item()\n",
    "watermarked_data = loaded_results['watermarked_data']\n",
    "\n",
    "def insert_tuples(temp, proportion):\n",
    "    num_insertions = int(proportion * len(temp))\n",
    "    sampled_rows = pd.DataFrame(columns=temp.columns)\n",
    "    \n",
    "    for column in temp.columns:\n",
    "        sampled_rows[column] = temp[column].sample(n=num_insertions, replace=True).reset_index(drop=True)\n",
    "    \n",
    "    insertion_indices = np.random.choice(len(temp) + num_insertions, size=num_insertions, replace=False)\n",
    "    expanded_temp = pd.DataFrame(index=range(len(temp) + num_insertions), columns=temp.columns)\n",
    "    original_indices = np.setdiff1d(np.arange(len(temp) + num_insertions), insertion_indices)\n",
    "    \n",
    "    expanded_temp.iloc[original_indices] = temp.values\n",
    "    expanded_temp.iloc[insertion_indices] = sampled_rows.values\n",
    "    \n",
    "    return expanded_temp\n",
    "\n",
    "\n",
    "for proportion in attack_proportion:\n",
    "    temp = watermarked_data.copy()\n",
    "    temp = insert_tuples(temp, proportion)\n",
    "    \n",
    "    temp.to_csv(f\"insertion_{dataset}-{seed}-{proportion}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect insertion\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "dataset = 'covertype'\n",
    "seed = 10000\n",
    "\n",
    "gamma = 1/2 # ratio between the length of green domain and red domain\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "origin = pd.read_csv(\"../dataset/covtype_with_key.subset.data\")\n",
    "\n",
    "proportions = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "for proportion in proportions:\n",
    "    loaded_results = np.load(f\"{dataset}-{seed}.npy\", allow_pickle=True).item()\n",
    "    watermarked_data = pd.read_csv(f\"insertion_{dataset}-{seed}-{proportion}.csv\")\n",
    "\n",
    "    cover_types = watermarked_data['Cover_Type'].unique()\n",
    "    cover_types.sort()  \n",
    "\n",
    "    green_cell = 0\n",
    "    n_cell = 0\n",
    "    \n",
    "    for idx in range(len(watermarked_data)):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        \n",
    "        selected_data = watermarked_data.loc[idx, columns_of_interest]\n",
    "        first_two_digits_data = selected_data.apply(first_two_digits)\n",
    "        composite_numbers = ''.join(first_two_digits_data.values)\n",
    "        \n",
    "        if(hash_mod(composite_numbers, 10) != 0):\n",
    "            continue\n",
    "        \n",
    "        n_cell += 1\n",
    "        \n",
    "        candidate_set = cover_types\n",
    "\n",
    "        shuffled_cover_types = list(cover_types)\n",
    "        np.random.shuffle(shuffled_cover_types)\n",
    "\n",
    "        half_size = len(shuffled_cover_types) // 2\n",
    "        green_domain = shuffled_cover_types[:half_size]\n",
    "        red_domain = shuffled_cover_types[half_size:]\n",
    "\n",
    "        if watermarked_data.loc[idx, 'Cover_Type'] in green_domain:\n",
    "            green_cell += 1\n",
    "    \n",
    "    # print(n_cell)\n",
    "    z_score = (green_cell - n_cell/2) / math.sqrt(n_cell/4)\n",
    "    print(f\"{proportion}: The z-score is \", z_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletion attack\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "seed = 10000\n",
    "np.random.seed(seed)\n",
    "attack_proportion = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "dataset = \"covertype\"\n",
    "loaded_results = np.load(f\"{dataset}-{seed}.npy\", allow_pickle=True).item()\n",
    "watermarked_data = loaded_results['watermarked_data']\n",
    "\n",
    "for proportion in attack_proportion:\n",
    "    temp = watermarked_data.copy()\n",
    "    indices = np.random.choice(len(temp), size=int(proportion * len(temp)), replace=False)\n",
    "    temp = temp.drop(indices)\n",
    "    temp.to_csv(f\"deletion_{dataset}-{seed}-{proportion}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect insertion\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "dataset = 'covertype'\n",
    "seed = 10000\n",
    "\n",
    "gamma = 1/2 # ratio between the length of green domain and red domain\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "origin = pd.read_csv(\"../dataset/covtype_with_key.subset.data\")\n",
    "\n",
    "proportions = [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "for proportion in proportions:\n",
    "    loaded_results = np.load(f\"{dataset}-{seed}.npy\", allow_pickle=True).item()\n",
    "    watermarked_data = pd.read_csv(f\"deletion_{dataset}-{seed}-{proportion}.csv\")\n",
    "\n",
    "    cover_types = watermarked_data['Cover_Type'].unique()\n",
    "    cover_types.sort()  \n",
    "\n",
    "    green_cell = 0\n",
    "    n_cell = 0\n",
    "    \n",
    "    for idx in range(len(watermarked_data)):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        \n",
    "        selected_data = watermarked_data.loc[idx, columns_of_interest]\n",
    "        first_two_digits_data = selected_data.apply(first_two_digits)\n",
    "        composite_numbers = ''.join(first_two_digits_data.values)\n",
    "        \n",
    "        if(hash_mod(composite_numbers, 10) != 0):\n",
    "            continue\n",
    "        \n",
    "        n_cell += 1\n",
    "        \n",
    "        candidate_set = cover_types\n",
    "\n",
    "        shuffled_cover_types = list(cover_types)\n",
    "        np.random.shuffle(shuffled_cover_types)\n",
    "\n",
    "        half_size = len(shuffled_cover_types) // 2\n",
    "        green_domain = shuffled_cover_types[:half_size]\n",
    "        red_domain = shuffled_cover_types[half_size:]\n",
    "\n",
    "        if watermarked_data.loc[idx, 'Cover_Type'] in green_domain:\n",
    "            green_cell += 1\n",
    "    \n",
    "    # print(n_cell)\n",
    "    z_score = (green_cell - n_cell/2) / math.sqrt(n_cell/4)\n",
    "    print(f\"{proportion}: The z-score is \", z_score)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watermark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
